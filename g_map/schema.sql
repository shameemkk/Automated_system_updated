create table public.client_queries (
 id bigint generated by default as identity primary key,
 client_tag text not null,
 query text not null,
 status text null default null,
 api_status text,
 region text,
 length int,
 latitude numeric(10,7),
 longitude numeric(10,7),
 mode text,
 created_at timestamp with time zone default timezone('utc'::text, now()) not null
);

-- fetch all data

-- create or replace function get_results_by_ids(query_ids int[])
-- returns setof client_query_results
-- language sql
-- as $$
--   select *
--   from client_query_results
--   where client_query_id = any(query_ids);
-- $$;


CREATE OR REPLACE FUNCTION get_results_by_automation_id(p_automation_id int)
RETURNS SETOF client_query_results
LANGUAGE sql
AS $$
  SELECT *
  FROM client_query_results
  WHERE automation_id = p_automation_id
    AND gpt_process = 'auto_completed'  -- Corrected spelling here
    AND mode = 'auto_email_verified';
$$;

-- check 2nd schedule

create or replace function check_bulk_gpt_status(query_ids int[])
returns json
language plpgsql
as $$
declare
  pending_list int[];
begin
  -- Find IDs that are "Pending"
  -- An ID is pending if a row exists that matches ANY of these conditions:
  -- 1. gpt_process is NOT 'auto_completed'
  -- 2. gpt_process IS NULL
  
  select array_agg(distinct q_id)
  into pending_list
  from unnest(query_ids) as q_id
  where exists (
    select 1 
    from client_query_results cqr 
    where cqr.client_query_id = q_id 
    and (
       cqr.gpt_process != 'auto_completed' 
       or cqr.gpt_process is null
    )
  );

  -- Return Logic
  if pending_list is null then
    return json_build_object(
      'status', 'completed',
      'pending_ids', '[]'::json
    );
  else
    return json_build_object(
      'status', 'pending',
      'pending_ids', pending_list
    );
  end if;
end;
$$;


-- -- new function using id 
-- CREATE OR REPLACE FUNCTION check_bulk_gpt_status(p_automation_id int)
-- RETURNS json
-- LANGUAGE plpgsql
-- AS $$
-- DECLARE
--   pending_list int[];
-- BEGIN
--   -- Find client_query_ids associated with this automation_id that are "Pending"
--   -- Condition: gpt_process is NOT 'auto_completed' OR is NULL
  
--   SELECT array_agg(client_query_id)
--   INTO pending_list
--   FROM client_query_results
--   WHERE automation_id = p_automation_id
--     AND (
--        gpt_process != 'auto_completed' 
--        OR gpt_process IS NULL
--     );

--   -- Return Logic
--   IF pending_list IS NULL THEN
--     RETURN json_build_object(
--       'status', 'completed',
--       'pending_ids', '[]'::json
--     );
--   ELSE
--     RETURN json_build_object(
--       'status', 'pending',
--       'pending_ids', pending_list
--     );
--   END IF;
-- END;
-- $$;




create or replace function check_automation_status(target_automation_id uuid)
returns json
language plpgsql
as $$
declare
  has_pending_rows boolean;
  rows_exist boolean;
begin
  -- 1. Check if any rows exist for this automation_id
  -- (Optional: prevents returning 'completed' for an ID that doesn't exist)
  select exists (
    select 1 from client_queries where automation_id = target_automation_id
  ) into rows_exist;

  if not rows_exist then
    return json_build_object('status', 'pending'); -- Or 'not_found' if you prefer
  end if;

  -- 2. Check if ANY row is NOT 'auto_completed'
  select exists (
    select 1 
    from client_queries 
    where automation_id = target_automation_id 
    and status != 'auto_completed'
  ) into has_pending_rows;

  -- 3. Return Logic
  if has_pending_rows then
    return json_build_object('status', 'pending');
  else
    return json_build_object('status', 'completed');
  end if;
end;
$$;






--- change and add automation_id --last use
-- select change_not_used_to_auto_queued('tag_A', p_batch_size, p_automation_id);
create or replace function change_not_used_to_auto_queued(
  p_client_tag text,
  p_batch_size int,
  p_automation_id bigint -- 1. Added new parameter
)
returns json
language plpgsql
as $$
declare
  v_result json;
begin
  with updated_rows as (
    update client_queries
    set 
      status = 'auto_queued',
      automation_id = p_automation_id -- 2. Update the automation_id column
    where id in (
      select q.id
      from client_queries q
      where q.client_tag = p_client_tag
        and q.status = 'not_used'
      order by q.created_at
      limit p_batch_size
      for update skip locked
    )
    returning id
  )
  select json_build_object(
    'client_tag', p_client_tag,
    'processing_ids', coalesce(array_agg(id::text), '{}'::text[])
  ) into v_result
  from updated_rows;

  return v_result;
end;
$$;


-- return all data 
-- create or replace function change_not_used_to_auto_queued(
--   p_client_tag text,
--   p_batch_size int
-- )
-- returns setof client_queries
-- language plpgsql
-- as $$
-- begin
--   return query
--   update client_queries
--   set status = 'auto_queued'
--   where id in (
--     select id
--     from client_queries
--     where client_tag = p_client_tag
--       and status = 'not_used'
--     order by created_at
--     limit p_batch_size
--     for update skip locked
--   )
--   returning *;
-- end;
-- $$;

-- get list of ids 
-- {
--   "client_tag": "tag_A",
--   "processing_ids": ["101", "105"]
-- }
-- create or replace function change_not_used_to_auto_queued(
--   p_client_tag text,
--   p_batch_size int
-- )
-- returns json -- Returns a single JSON object
-- language plpgsql
-- as $$
-- declare
--   v_result json;
-- begin
--   with updated_rows as (
--     update client_queries
--     set status = 'auto_queued'
--     where id in (
--       select q.id
--       from client_queries q
--       where q.client_tag = p_client_tag
--         and q.status = 'not_used'
--       order by q.created_at
--       limit p_batch_size
--       for update skip locked
--     )
--     returning id
--   )
--   select json_build_object(
--     'client_tag', p_client_tag,
--     -- We cast ID to text (id::text) so the JSON output is ["1", "2"] 
--     -- instead of [1, 2]. This is safer for JS clients consuming BigInts.
--     'processing_ids', coalesce(array_agg(id::text), '{}'::text[])
--   ) into v_result
--   from updated_rows;

--   return v_result;
-- end;
-- $$;


-- all data return

-- create or replace function change_not_used_to_auto_queued(
--   p_client_tag text,
--   p_batch_size int
-- )
-- returns setof client_queries
-- language plpgsql
-- as $$
-- begin
--   return query
--   update client_queries
--   set status = 'auto_queued'
--   where id in (
--     select id
--     from client_queries
--     where client_tag = p_client_tag
--       and status = 'not_used'
--     order by created_at
--     limit p_batch_size
--     for update skip locked
--   )
--   returning *;
-- end;
-- $$;


create or replace function fetch_queries(
  p_batch_size int
)
returns setof client_queries
language plpgsql
as $$
begin
  return query
  update client_queries
  set status = 'processing'
  where id in (
    select id
    from client_queries
    where status = 'queued'
    order by client_tag, created_at
    limit p_batch_size
    for update skip locked
  )
  returning *;
end;
$$;

-- Client details table to store ZIP code filters per client_tag
create table if not exists public.client_details (
  id bigint generated by default as identity primary key,
  client_tag text not null unique,
  zip_codes_format text[] not null,
  created_at timestamp with time zone default timezone('utc'::text, now()) not null
);

create table public.client_query_results (
  id bigint generated by default as identity primary key,
  client_query_id bigint not null references client_queries(id) on delete cascade,
  client_tag text not null,
  name text,
  website text unique,
  types text[],
  zip_code text,
  phone_number text,
  full_address text,
  city text,
  place_link text,
  timezone text,
  review_count int,
  rating numeric(2,1),
  mode text,
  verified_emails text[],
  created_at timestamp with time zone default timezone('utc'::text, now()) not null
);



-- email scraper 

create table if not exists public.email_scraper_node (
  id bigint generated by default as identity not null,
  client_query_result_id bigint references client_query_results(id) on delete cascade,
  url text not null,
  client_tag text not null,
  status text null,
  facebook_urls text[] null,
  emails text[] null,
  message text null,
  retry_count integer not null default 0,
  updated_at timestamp with time zone not null default now(),
  scrape_type text not null default 'http_request',
  needs_browser_rendering boolean not null default false,
  created_at timestamp with time zone not null default now(),
  constraint email_scraper_node_pkey primary key (id)
) TABLESPACE pg_default;

-- Trigger function to add website to email_scraper_node when client_query_results is inserted
create or replace function add_website_to_email_scraper()
returns trigger
language plpgsql
as $$
begin
  -- Only insert if website is not null or empty
  if NEW.website is not null and NEW.website != '' then
      insert into email_scraper_node (url, client_tag, status, client_query_result_id)
      values (NEW.website, NEW.client_tag, 'queued', NEW.id);
  end if;

  return NEW;
end;
$$;

-- Create trigger on client_query_results table
drop trigger if exists trg_add_website_to_email_scraper on client_query_results;
create trigger trg_add_website_to_email_scraper
after insert on client_query_results
for each row
execute function add_website_to_email_scraper();


-- Cron function to reset error status to queued for retry
create or replace function reset_error_to_queued()
returns void
language plpgsql
as $$
begin
  update client_queries
  set status = 'queued'
  where status = 'error';
end;
$$;

-- Cron function to copy auto mode results to email_scraper_node
create or replace function process_auto_results_to_email_scraper()
returns void
language plpgsql
as $$
declare
  processed_count int;
begin
  -- Insert websites from client_query_results where mode='auto' into email_scraper_node
  with inserted as (
    insert into email_scraper_node (url, client_tag, status, mode)
    select 
      website,
      client_tag,
      'auto_queued',
      'auto'
    from client_query_results
    where mode = 'auto'
      and website is not null
      and website != ''
    returning *
  )
  select count(*) into processed_count from inserted;

  -- Update mode to 'auto_taken' for processed results
  update client_query_results
  set mode = 'auto_taken'
  where mode = 'auto'
    and website is not null
    and website != '';

  -- Log the count (optional, for monitoring)
  raise notice 'Processed % auto results to email_scraper_node', processed_count;
end;
$$;

-- Enable pg_cron extension (run this as superuser if not already enabled)
-- create extension if not exists pg_cron;

-- Schedule the cron job to run every 5 minutes
select cron.schedule(
  'reset-error-queries',
  '*/5 * * * *',
  $$ select reset_error_to_queued(); $$
);

-- Schedule the cron job to process auto results every minute
select cron.schedule(
  'process-auto-results',
  '* * * * *',
  $$ select process_auto_results_to_email_scraper(); $$
);

-- To unschedule: select cron.unschedule('reset-error-queries');
-- To unschedule: select cron.unschedule('process-auto-results');

-- New RPC function to fetch auto_queued and auto_error rows
create or replace function fetch_auto_queries(
  p_batch_size int
)
returns setof client_queries
language plpgsql
as $$
begin
  return query
  update client_queries
  set status = 'auto_processing'
  where id in (
    select id
    from client_queries
    where status in ('auto_queued', 'auto_error')
    order by 
      case when status = 'auto_queued' then 0 else 1 end,
      client_tag, 
      created_at
    limit p_batch_size
    for update skip locked
  )
  returning *;
end;
$$;

