create type processing_status as enum ('not_used','queued','processing','completed','error');

create table public.client_queries (
 id bigint generated by default as identity primary key,
 client_tag text not null,
 query text not null,
 status processing_status not null default 'not_used',
 api_status text,
 region text,
 length int,
 latitude numeric(10,7),
 longitude numeric(10,7),
 created_at timestamp with time zone default timezone('utc'::text, now()) not null
);



create or replace function change_not_used_to_queued(
  p_client_tag text,
  p_batch_size int
)
returns setof client_queries
language plpgsql
as $$
begin
  return query
  update client_queries
  set status = 'queued'
  where id in (
    select id
    from client_queries
    where client_tag = p_client_tag
      and status = 'not_used'
    order by created_at
    limit p_batch_size
    for update skip locked
  )
  returning *;
end;
$$;

create or replace function fetch_queries(
  p_batch_size int
)
returns setof client_queries
language plpgsql
as $$
begin
  return query
  update client_queries
  set status = 'processing'
  where id in (
    select id
    from client_queries
    where status = 'queued'
    order by client_tag, created_at
    limit p_batch_size
    for update skip locked
  )
  returning *;
end;
$$;

create table public.client_query_results (
  id bigint generated by default as identity primary key,
  client_query_id bigint not null references client_queries(id) on delete cascade,
  client_tag text not null,
  name text,
  website text unique,
  types text[],
  zip_code text,
  phone_number text,
  full_address text,
  city text,
  place_link text,
  timezone text,
  review_count int,
  rating numeric(2,1),
  verified_emails text[],
  created_at timestamp with time zone default timezone('utc'::text, now()) not null
);



-- email scraper 

create table if not exists public.email_scraper_node (
  id bigint generated by default as identity not null,
  client_query_result_id bigint references client_query_results(id) on delete cascade,
  url text not null,
  client_tag text not null,
  status text null,
  facebook_urls text[] null,
  emails text[] null,
  message text null,
  retry_count integer not null default 0,
  updated_at timestamp with time zone not null default now(),
  scrape_type text not null default 'http_request',
  needs_browser_rendering boolean not null default false,
  created_at timestamp with time zone not null default now(),
  constraint email_scraper_node_pkey primary key (id)
) TABLESPACE pg_default;

-- Trigger function to add website to email_scraper_node when client_query_results is inserted
create or replace function add_website_to_email_scraper()
returns trigger
language plpgsql
as $$
begin
  -- Only insert if website is not null or empty
  if NEW.website is not null and NEW.website != '' then
      insert into email_scraper_node (url, client_tag, status, client_query_result_id)
      values (NEW.website, NEW.client_tag, 'queued', NEW.id);
  end if;

  return NEW;
end;
$$;

-- Create trigger on client_query_results table
drop trigger if exists trg_add_website_to_email_scraper on client_query_results;
create trigger trg_add_website_to_email_scraper
after insert on client_query_results
for each row
execute function add_website_to_email_scraper();


-- Cron function to reset error status to queued for retry
create or replace function reset_error_to_queued()
returns void
language plpgsql
as $$
begin
  update client_queries
  set status = 'queued'
  where status = 'error';
end;
$$;

-- Enable pg_cron extension (run this as superuser if not already enabled)
-- create extension if not exists pg_cron;

-- Schedule the cron job to run every 5 minutes
select cron.schedule(
  'reset-error-queries',
  '*/5 * * * *',
  $$ select reset_error_to_queued(); $$
);

-- To unschedule: select cron.unschedule('reset-error-queries');
